{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a43ab369-27a8-451d-9501-eb837712ad7d",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda4e1c2-ddfb-43b6-af19-7e9a06cc253a",
   "metadata": {},
   "source": [
    "- `컴퓨터 비전` 문제에 가장 main 으로 사용되는 풀이의 정수\n",
    "- 물체 탐지 기술을 잘 구현하여 자율주행 , 장기 탐지 , 사람 행동감지 등에 폭넓은 분야에서 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630d65a8-d4a2-4e1c-8210-b2c07c72d0b8",
   "metadata": {},
   "source": [
    "> **`CNN`** 을 사용하면 이미지 데이터를 사용하여 학습할 때 주요하게 봐야할 것은 CNN 기술뿐아니라 `data augmentation(데이터 증강, 데이터늘리기)` , `batch normalization(배치정규화)` 도 주의깊게 살펴보아야합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e8f559-2369-4cf5-a865-eb303458fc85",
   "metadata": {},
   "source": [
    "# CNN 설명 [1]"
   ]
  },
  {
   "attachments": {
    "9248e242-83d8-4aff-a841-d0a59196a4cd.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "5c7ff073-228d-4f5d-b23d-3a68b9c939b6",
   "metadata": {},
   "source": [
    "## `-` Why CNN used for image?\n",
    "\n",
    "1. 이미지는 픽셀로 이루어져있다.\n",
    "2. 픽셀은 행렬로써 `숫자들의 행렬`로 표현할 수 있다.\n",
    "3. `flatten` 로 픽셀을 한 줄의 벡터로 펼쳐서 계산할 수 있다.\n",
    "\n",
    "![download.png](attachment:9248e242-83d8-4aff-a841-d0a59196a4cd.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cf0818-6fd7-4bf0-8ed0-062040bd913d",
   "metadata": {},
   "source": [
    "`-` flatten 의 단점 : 이미지분석시에 이미지는 상호픽셀간의 유의미한 관계가 있다. (고양이라면 고양이 눈 주변의 픽셀들이 눈썹,흰자,검은자 등의 색에 관련되어서 숫자가 비슷하고 대조적으로 분류가 될 것이다.) 이 관계를 flatten 으로 모두 잃어 버리게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f9867d2-2b49-4c20-a50b-c6cd470cde4f",
   "metadata": {},
   "source": [
    "## 그래서 CNN 을 사용한다.\n",
    "\n",
    "### `-` CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8199a7-ae20-4ba0-b347-9c7000261aa6",
   "metadata": {},
   "source": [
    "- CNN 기술로 부분적인 의존성을 캐치할 수 있고 (capturing the spatial dependencies) 덩어리끼리의 분석을 완전히 가능하게 한다.\n",
    "\n",
    "- 각각의 이미지 덩어리는 일정 파라미터가 부여되고 `filter` 라는 것을 거치면서 좋은 가중치(weights)를 만들게한다.\n",
    "\n",
    "- CNN 은 parameter 를 줄이면서 이미지를 분석하고 rendering 을 진행시켜 그 이미지의 특징을 분석할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640bbfde-943d-43d2-8016-3048b15e4cb9",
   "metadata": {},
   "source": [
    "## `-` CNN 의 input\n",
    "\n",
    "`-` input <br>\n",
    "image 이므로 0-255 의 색상이 존재 + 이미지의 픽셀수 + RGB 이다.\n",
    "\n",
    "`-`\n",
    "이미지의 픽셀수가 4x4 라면 4x4x3 또는 3x4x4 형태로 만들 수 있다.\n",
    "<br>\n",
    "`3` = RGB 로 1번 행렬은 R,  2번 행렬은 G , 3번 행렬은 B 가 들어가게 되어 이를 3개의 채널을 가지고 있다고 말한다.\n",
    "<br>\n",
    "3x4x4 는 3개의 채널(RGB)로 이루어진 4x4 행렬이다. (16개의 픽셀은 모두 0-255 의 숫자중 하나로 구성되어있기 때문이다.)\n",
    "<br>\n",
    "`-` channel <br>\n",
    "RGB 가 3개의 채널도 되어있다고 하였는데 채널은 더 넓은 의미에서 쓰인다.\n",
    "<br>\n",
    "RGB 는 채널이 3개 명확하지만 앞으로 `filter` 를 거치면서 학습을 하면 채널의 수가 늘어났다가 줄어들며 학습을 진행하고 이 채널의 개수 자체가 가지는 의미는 딱히 없으며 채널의 수에 따라 학습을 더 잘하고 못하고는 결정될 수 있다. \n",
    "<br>\n",
    "`-` filter <br>\n",
    "filter 는 CNN 의 이미지를 처리하는 하나의 필터로 이전의 예시의 3x4x4 의 이미지에 연산을 진행시키는 행렬이다. 가볍게 image * filter => 새로운 image(이 이미지는 사람이 해석할 수 없고 숫자 계산단계라고 생각하면 편하다)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac4b2b9-3de3-4938-9341-ea31dd5a17c1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "## `-` CNN 의 output\n",
    "`-` output <br>\n",
    "image matrix size = $h * w * c$ <br>\n",
    "filter size = $f_h * f_w * c $ <br>\n",
    "$output$ $ height =h- f_h +1$  <br>\n",
    "$output$ $ width = w - f_w + 1 $ <br>\n",
    "$output$ $ depth = 1 $ #depth = channel"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c62152be-4e97-4dd9-b0d0-9c5fc72a25e6",
   "metadata": {},
   "source": [
    "CNN 실전 계산해보기 - CNN 의 계산과정을 Convolution 계산이라고 합니다.\n",
    "\n",
    "실전계산은 쉽고 외울게 많으므로 부록에서 실시하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85da948a-63ad-4b7b-a8df-4dc87aac7940",
   "metadata": {},
   "source": [
    "## `-` CNN 의 fully connected layers\n",
    "<br>\n",
    "\n",
    "`fully connected layers` 는 `FC layer` 이라고도 불린다. (FC layer 는 크게보면 기초이론상 모두 연결된 layer 로 DNN 을 초기에 설명할 때 자주 나왔던 perceptron 에 선이 연결된 모습이다.)\n",
    "<br>\n",
    "`fc layer` 는 cnn 의 한 사이클의 마지막 단계로 output data 이 나오기 직전단계이다.\n",
    "<br>\n",
    "[순서] <br>\n",
    "`CNN과정` -> `flatten` -> `FC layer층` -> `output`\n",
    "<br>\n",
    "\n",
    "### `FC layer` 의 목적\n",
    "`-` 분류를 위해 탐지된 모든 특징들을 고려하는 것.\n",
    "<br>\n",
    "`-` 보통의 FC layers 는 activation function(활성화함수)를 지나갔지만 현재 마지막에 사용하는 FC layer 는 softmax function 을 지나간다. ( FC layer 층은 여러개의 층으로 이루어져있다.)\n",
    "\n",
    "<br>\n",
    "\n",
    "`-` 첫 input size of FC layer\n",
    "-  flatten 이 된 후의 벡터이다. 예를들어 3x3 이 마지막에 나온 사진이라면 이를 flatten 진행하여 9x1 이 된다.\n",
    "<br>\n",
    "`-` 마지막 output size of FC layer\n",
    "- 이건 사용자가 정할 수 있고 정확하게 결정되어 있는 것이 아니고 마음대로 커스터마이징이 가능하다.\n",
    "- 마지막 FC layer 는 class labels 의 개수와 마지막 크기를 맞추어주어야한다. (예를들어, MNIST 데이터에서 0~9 까지 숫자로 나와야한다면 class labels= 10 , 또는 cat and dogs 라면 class labels = 2 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cc8e11-ed2a-427e-a292-35bc6feb5f5e",
   "metadata": {},
   "source": [
    "# `FC layers` 코드\n",
    "```python\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN_network(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CNN_network,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3,18,3,1,1)\n",
    "        self.pool1 = nn.MaxPool2d(2,2)\n",
    "        self.linear1 = nn.Linear(32*32*16,64)\n",
    "        self.linear2 = nn.Linear(64,10)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x= F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = x.view(-1,32*32*16) #현재 flatten 하는 코드\n",
    "        x = F.relu(self.linear1(x)) #32*32*16 의 크기가 flatten 되어 숫자로나오고 64개의 parameter 로 바꿔주는 부분.\n",
    "        x = F.log_softmax(self.linear2(x),dim=1) # 마지막부분에 softmax 사용해주는 모습.\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f744d71-8b2f-4d68-b7ae-f89b9ed10872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
