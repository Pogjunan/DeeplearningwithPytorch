{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "111e2fb3-d163-4848-8f7f-1c13dce0b044",
   "metadata": {},
   "source": [
    "# [9] Pytorch 에서 데이터 다운로드받기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66012e06-e07b-409a-9e8f-4356c1b386e2",
   "metadata": {},
   "source": [
    "- 대회를 준비한다면 가장 중요한 입문 파트!\n",
    "\n",
    "`-`dataset 을 pytorch 를 통해 다운로드받고 이 데이터를 변형시키는 것까지 진행하겠습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e6001c2-a687-4d5f-9c3c-e7009f7bd803",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = \\\n",
    "transforms.Compose([transforms.ToTensor(), \\\n",
    "                   transforms.Normalize((0.5,0.5,0.5),\n",
    "                                        (0.5,0.5,0.5))])\n",
    "\n",
    "#torchvision 은 https://pytorch.org/vision/stable/index.html 에서 더욱 자세한 내용을 확인할 수 있습니다.\n",
    "# transform 은 변화시켜주는 것으로 Compose 내부의 명령대로 변화시켜주며 현재는 텐서로 바꾸고 정규화 시킨 모습을 보이고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71a776dc-d353-4837-8d51-e7f08a31e679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    ToTensor()\n",
       "    Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2af95018-cad9-46dd-85ba-7e744fed7e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.MNIST(root='data',train = True, \n",
    "                            download = True, transform =transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "292b540d-8b93-4765-97a8-d17b2e9a80fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = datasets.MNIST(root='data',train=False,\n",
    "                           download=True,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffd68bce-7b4c-4ea0-af1d-26591dfeb5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29adabb3-76af-41c3-b6ea-ecde3a82214e",
   "metadata": {},
   "source": [
    "# `train_test_split 함수`의 작동원리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "089ee980-d4c2-4ad3-bf74-e7f602ea12c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_size = 0.2 # test데이터를 20%비율\n",
    "idx = list(range(len(train_data))) #idx = index\n",
    "np.random.shuffle(idx)\n",
    "split_size = int(np.floor(dev_size * len(train_data)))\n",
    "train_idx,dev_idx = idx[split_size:], idx[:split_size] #이게"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d59579b-3894-440c-b044-15397c3a04fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "dev_sampler = SubsetRandomSampler(dev_idx)\n",
    "#train set 내부를 둘로 나누고 dev set 내부도 둘로 나눈 것입니다.(training 과 validation 으로)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "40f8560a-3b63-4230-b097-f5da7c62bfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=20\n",
    "\n",
    "train_loader= torch.utils.data.DataLoader(train_data,batch_size=batch_size,sampler=train_sampler)\n",
    "dev_loader= torch.utils.data.DataLoader(train_data,batch_size=batch_size,sampler=dev_sampler)\n",
    "test_loader= torch.utils.data.DataLoader(test_data,batch_size=batch_size)\n",
    "\n",
    "# DataLoader 함수는 이미지를 배치단위로 로드합니다.\n",
    "#먼저, 세트를 포함하는 변수가 인수로 전달되고, 그런 다음 배치 크기가 정의됩니다.\n",
    "# 그리고 sampler 가 각각의 반복(iteration)에서 랜덤하게 생성되고 모델 수행력을 높입니다.\n",
    "# 결론적으로 train_loader 과 같은 각각의 변수는 feature 와 target 을 따로따로 포함하고 있게 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb17955d-0592-47d2-b927-92146e5dda08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep",
   "language": "python",
   "name": "deep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
